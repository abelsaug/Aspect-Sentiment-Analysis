{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around with Word Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Count Vectorized with aspect weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aspdep_weight(train_df, weight):\n",
    "    train_text = train_df[' text'].values.astype('U')\n",
    "    train_aspdep = train_df['asp_dep_words'].values.astype('U')\n",
    "    text_count_vect = CountVectorizer()\n",
    "    x_text_counts = text_count_vect.fit_transform(train_text)\n",
    "    text_voc = text_count_vect.vocabulary_\n",
    "    asp_dep_vect = CountVectorizer(vocabulary=text_voc)\n",
    "    x_aspdep_counts = asp_dep_vect.fit_transform(train_aspdep)\n",
    "    x_count_vec = x_text_counts + weight * x_aspdep_counts\n",
    "    x_tfidf_vec = TfidfTransformer(use_idf=True).fit_transform(x_count_vec)\n",
    "    return x_tfidf_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Count Vectorized with aspect weight distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspect_related_words(sdp, ardf):\n",
    "    print(\"Extracting aspect related words from text...\")\n",
    "    cols = list(ardf)\n",
    "    cols.append('asp_dep_words')\n",
    "    ar_df = pandas.DataFrame(columns=cols)\n",
    "    count = 0\n",
    "    for index, row in ardf.iterrows():\n",
    "        count += 1\n",
    "        print(count)\n",
    "        dep_set = set()\n",
    "        result = list(sdp.raw_parse(row[' text']))\n",
    "        parse_triples_list = [item for item in result[0].triples()]\n",
    "        for governor, dep, dependent in parse_triples_list:\n",
    "            print(\"G: \", governor, \"DEP: \", dep, \"depndent: \",dependent)\n",
    "            if governor[0] in row[' aspect_term'] or dependent[0] in row[' aspect_term']:\n",
    "                dep_set.add(governor[0])\n",
    "                dep_set.add(dependent[0])\n",
    "        ar_row = [row[c] for c in cols[:-1]]\n",
    "        ar_row.append(' '.join(list(dep_set)))\n",
    "        ar_df.loc[len(ar_df.index)] = ar_row\n",
    "    return ar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting aspect related words from text...\n",
      "1\n",
      "G:  ('features', 'VBZ') DEP:  advmod depndent:  ('Obviously', 'RB')\n",
      "G:  ('features', 'VBZ') DEP:  nsubj depndent:  ('one', 'PRP')\n",
      "G:  ('features', 'VBZ') DEP:  advmod depndent:  ('important', 'JJ')\n",
      "G:  ('features', 'VBZ') DEP:  dobj depndent:  ('interface', 'NN')\n",
      "G:  ('interface', 'NN') DEP:  compound depndent:  ('computer', 'NN')\n",
      "G:  ('interface', 'NN') DEP:  amod depndent:  ('human', 'JJ')\n",
      "2\n",
      "G:  ('browsing', 'VBD') DEP:  nsubj depndent:  ('web', 'NN')\n",
      "G:  ('web', 'NN') DEP:  amod depndent:  ('Good', 'JJ')\n",
      "G:  ('Good', 'JJ') DEP:  nmod:tmod depndent:  ('day', 'NN')\n",
      "G:  ('day', 'NN') DEP:  det depndent:  ('every', 'DT')\n",
      "G:  ('web', 'NN') DEP:  amod depndent:  ('computing', 'VBG')\n",
      "3\n",
      "G:  ('makes', 'VBZ') DEP:  nsubj depndent:  ('alright', 'NN')\n",
      "G:  ('alright', 'NN') DEP:  compound depndent:  ('keyboard', 'NN')\n",
      "G:  ('alright', 'NN') DEP:  appos depndent:  ('plate', 'NN')\n",
      "G:  ('plate', 'NN') DEP:  nmod depndent:  ('plastic', 'NN')\n",
      "G:  ('plastic', 'NN') DEP:  case depndent:  ('around', 'IN')\n",
      "G:  ('plastic', 'NN') DEP:  amod depndent:  ('cheap', 'JJ')\n",
      "G:  ('makes', 'VBZ') DEP:  dobj depndent:  ('sound', 'NN')\n",
      "G:  ('sound', 'NN') DEP:  amod depndent:  ('hollow', 'JJ')\n",
      "G:  ('sound', 'NN') DEP:  acl depndent:  ('using', 'VBG')\n",
      "G:  ('using', 'VBG') DEP:  dobj depndent:  ('buttons', 'NNS')\n",
      "G:  ('buttons', 'NNS') DEP:  compound depndent:  ('mouse', 'NN')\n",
      "G:  ('buttons', 'NNS') DEP:  compound depndent:  ('command', 'NN')\n",
      "4\n",
      "G:  ('work', 'VBP') DEP:  advmod depndent:  ('Again', 'RB')\n",
      "G:  ('work', 'VBP') DEP:  nsubj depndent:  ('speaker', 'NN')\n",
      "G:  ('speaker', 'NN') DEP:  compound depndent:  ('problem', 'NN')\n",
      "G:  ('speaker', 'NN') DEP:  amod depndent:  ('right', 'JJ')\n",
      "5\n",
      "G:  ('problem', 'NN') DEP:  nmod:poss depndent:  ('My', 'PRP$')\n",
      "G:  ('problem', 'NN') DEP:  dep depndent:  ('Service', 'NNP')\n",
      "G:  ('Service', 'NNP') DEP:  compound depndent:  ('DELL', 'NNP')\n",
      "G:  ('Service', 'NNP') DEP:  compound depndent:  ('Customer', 'NNP')\n",
      "                                                text            aspect_term  \\\n",
      "0  Obviously one important features computer huma...        human interface   \n",
      "1             Good every day computing web browsing.    every day computing   \n",
      "2  keyboard alright, plate around cheap plastic m...  mouse command buttons   \n",
      "3                Again, problem, right speaker work.          right speaker   \n",
      "4                  My problem DELL Customer Service.  DELL Customer Service   \n",
      "\n",
      "                       asp_dep_words  \n",
      "0  features human interface computer  \n",
      "1       computing day Good web every  \n",
      "2        using command mouse buttons  \n",
      "3         problem speaker right work  \n",
      "4      problem DELL Service Customer  \n"
     ]
    }
   ],
   "source": [
    "##TEST CELL\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "import pandas\n",
    "import nltk\n",
    "nltk.internals.config_java(\"C:\\Program Files\\Java\\jdk1.8.0_171\\\\bin\\java.exe\")\n",
    "sdp = StanfordDependencyParser(\n",
    "    path_to_jar=\"stanford-nlp-jars\\stanford-corenlp-full-2018-01-31\\stanford-corenlp-3.9.0.jar\",\n",
    "    path_to_models_jar=\"stanford-nlp-jars\\stanford-corenlp-full-2018-01-31\\stanford-corenlp-3.9.0-models.jar\")\n",
    "test_df = pandas.read_csv('test_1.csv', sep='\\t')\n",
    "print(extract_aspect_related_words(sdp, test_df[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding based on co-ocurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             10  11  13  159  16  20  2008  2011  24  250 ...   would  wouldn  \\\n",
      "10            0   0   0    0   0   1     0     0   0    0 ...       1       0   \n",
      "11            0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "13            0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "159           0   0   0    0   0   0     1     0   0    0 ...       1       0   \n",
      "16            0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "20            1   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "2008          0   0   0    1   0   0     0     0   0    0 ...       1       0   \n",
      "2011          0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "24            0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "250           0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "300           0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "320gb         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "350           0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "3g            0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "400           0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "500gb         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "5870          0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "720p          0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "80            1   0   0    0   0   1     0     0   0    0 ...       0       0   \n",
      "8gb           0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "ability       0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "able          0   0   0    0   0   0     0     0   0    0 ...       1       0   \n",
      "absolutely    0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "accent        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "access        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "accordingly   0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "account       0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "acer          0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "acknowledge   0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "action        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "...          ..  ..  ..  ...  ..  ..   ...   ...  ..  ... ...     ...     ...   \n",
      "while         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "white         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "whole         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "win           0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "window        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "windows       0   0   0    1   0   0     1     0   0    0 ...       1       0   \n",
      "wiped         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "wireless      0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "wish          0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "within        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "without       0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "wonderful     0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "wont          0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "word          1   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "work          0   0   0    0   0   0     0     0   0    0 ...       1       1   \n",
      "worked        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "working       0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "works         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "worlds        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "worth         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "would         1   0   0    1   0   0     1     0   0    0 ...       0       0   \n",
      "wouldn        0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "writing       0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "wrong         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "xp            0   0   0    1   0   0     1     0   0    0 ...       1       0   \n",
      "yeah          0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "year          1   0   0    0   0   1     0     0   0    0 ...       0       0   \n",
      "years         0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "yet           0   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "you           1   0   0    0   0   0     0     0   0    0 ...       0       0   \n",
      "\n",
      "             writing  wrong  xp  yeah  year  years  yet  you  \n",
      "10                 0      0   0     0     1      0    0    1  \n",
      "11                 0      0   0     0     0      0    0    0  \n",
      "13                 0      0   0     0     0      0    0    0  \n",
      "159                0      0   1     0     0      0    0    0  \n",
      "16                 0      0   0     0     0      0    0    0  \n",
      "20                 0      0   0     0     1      0    0    0  \n",
      "2008               0      0   1     0     0      0    0    0  \n",
      "2011               0      0   0     0     0      0    0    0  \n",
      "24                 0      0   0     0     0      0    0    0  \n",
      "250                0      0   0     0     0      0    0    0  \n",
      "300                0      0   0     0     1      0    0    0  \n",
      "320gb              0      0   0     0     0      0    0    0  \n",
      "350                0      0   0     0     0      0    0    0  \n",
      "3g                 0      0   0     0     0      0    0    0  \n",
      "400                0      0   0     0     0      1    0    0  \n",
      "500gb              0      0   0     0     0      0    0    0  \n",
      "5870               0      0   0     0     0      0    0    0  \n",
      "720p               0      0   0     0     0      0    0    0  \n",
      "80                 0      0   0     0     1      0    0    0  \n",
      "8gb                0      0   0     0     0      0    0    0  \n",
      "ability            0      0   0     0     0      0    0    0  \n",
      "able               0      1   0     0     0      0    0    0  \n",
      "absolutely         0      0   0     0     0      0    0    1  \n",
      "accent             0      0   0     0     0      0    0    0  \n",
      "access             0      0   0     0     0      1    0    0  \n",
      "accordingly        0      0   0     0     1      1    0    0  \n",
      "account            0      0   0     0     0      0    0    0  \n",
      "acer               0      0   0     0     0      0    1    0  \n",
      "acknowledge        0      0   0     0     0      0    0    0  \n",
      "action             0      0   0     0     0      0    0    0  \n",
      "...              ...    ...  ..   ...   ...    ...  ...  ...  \n",
      "while              0      0   0     0     0      0    0    0  \n",
      "white              0      0   0     0     0      0    0    0  \n",
      "whole              0      0   0     0     0      0    0    0  \n",
      "win                0      0   0     0     0      0    0    0  \n",
      "window             0      0   0     0     0      0    0    1  \n",
      "windows            0      0   2     0     0      0    0    0  \n",
      "wiped              0      0   0     0     0      0    0    0  \n",
      "wireless           0      0   0     0     0      0    0    0  \n",
      "wish               0      0   0     0     0      0    0    0  \n",
      "within             0      0   0     0     0      0    0    0  \n",
      "without            0      0   2     0     0      1    0    1  \n",
      "wonderful          0      0   0     0     0      0    0    0  \n",
      "wont               0      0   0     0     0      0    0    0  \n",
      "word               0      0   0     0     0      0    0    1  \n",
      "work               0      0   0     0     0      0    0    0  \n",
      "worked             0      0   0     0     0      1    0    0  \n",
      "working            0      1   0     0     1      0    0    1  \n",
      "works              0      0   0     0     0      0    0    0  \n",
      "worlds             0      0   0     0     0      0    0    0  \n",
      "worth              0      0   0     0     0      0    0    0  \n",
      "would              0      0   1     0     0      0    0    0  \n",
      "wouldn             0      0   0     0     0      0    0    0  \n",
      "writing            0      0   0     0     0      0    0    0  \n",
      "wrong              0      0   0     0     0      0    0    0  \n",
      "xp                 0      0   0     0     0      0    0    0  \n",
      "yeah               0      0   0     0     0      0    0    0  \n",
      "year               0      0   0     0     0      1    0    0  \n",
      "years              0      0   0     0     1      0    0    0  \n",
      "yet                0      0   0     0     0      0    0    0  \n",
      "you                0      0   0     0     0      0    0    0  \n",
      "\n",
      "[1058 rows x 1058 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "def apply_aspdep_weight(train_df):\n",
    "    train_text = train_df[' text'].values.astype('U')\n",
    "#     train_aspdep = train_df['asp_dep_words'].values.astype('U')\n",
    "    text_count_vect = CountVectorizer()\n",
    "    x_text_counts = text_count_vect.fit_transform(train_text)\n",
    "    Xc = (x_text_counts.T * x_text_counts)\n",
    "    Xc.setdiag(0)\n",
    "    print(pd.DataFrame(Xc.todense(), \n",
    "    columns=text_count_vect.get_feature_names(), \n",
    "    index=text_count_vect.get_feature_names()))\n",
    "apply_aspdep_weight(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
